{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Preprocessing from package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports packages and sample .txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking virtualenv with `pyenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.7.7/envs/IIPE (created from /Users/alexisgourdol/.pyenv/versions/lewagon)\n",
      "  3.7.7/envs/article2db (created from /Users/alexisgourdol/.pyenv/versions/3.7.7)\n",
      "  3.7.7/envs/lewagon (created from /Users/alexisgourdol/.pyenv/versions/3.7.7)\n",
      "* IIPE (created from /Users/alexisgourdol/.pyenv/versions/lewagon)\n",
      "  article2db (created from /Users/alexisgourdol/.pyenv/versions/3.7.7)\n",
      "  lewagon (created from /Users/alexisgourdol/.pyenv/versions/3.7.7)\n"
     ]
    }
   ],
   "source": [
    "!pyenv virtualenvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "Python 3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IIPE.preproc import make_contents_df, make_tokens\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Select the data_samples to read .txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexisgourdol/code/alexisgourdol/IIPE-data/notebooks\n",
      "/Users/alexisgourdol/code/alexisgourdol/IIPE-data/IIPE/data_sample/plain_text_sample\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(os.path.join('..', 'IIPE', 'data_sample', 'plain_text_sample'))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reports_Plain text_03220F_15_11_2019.txt',\n",
       " 'Reports_Plain text_01300Q_08_10_2020.txt',\n",
       " 'Results\\\\Word count\\\\Whole sample.png',\n",
       " 'Reports_Plain text_03917V_23_09_2020.txt',\n",
       " 'Reports_Plain text_05933G_08_10_2020.txt',\n",
       " 'Reports_Plain text_07518E_15_12_2020.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = os.listdir()\n",
    "file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use our preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>reference</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>03220F</td>\n",
       "      <td>Whole-School Evaluation – Management, Leadersh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>01300Q</td>\n",
       "      <td>Whole-School Evaluation – Management, Leadersh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>03917V</td>\n",
       "      <td>Whole-School Evaluation – Management, Leadersh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>05933G</td>\n",
       "      <td>Whole-School Evaluation – Management, Leadersh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>07518E</td>\n",
       "      <td>Whole-School Evaluation – Management, Leadersh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date reference                                               text\n",
       "0 2019-11-15    03220F  Whole-School Evaluation – Management, Leadersh...\n",
       "1 2020-10-08    01300Q  Whole-School Evaluation – Management, Leadersh...\n",
       "2 2020-09-23    03917V  Whole-School Evaluation – Management, Leadersh...\n",
       "3 2020-10-08    05933G  Whole-School Evaluation – Management, Leadersh...\n",
       "4 2020-12-15    07518E  Whole-School Evaluation – Management, Leadersh..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contents = make_contents_df(file_names)\n",
    "df_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040  tokens available. Here are the 5 first in no particular order: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['evaluation', 'leadership', 'date', 'inspection', 'inspection']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = make_tokens(df_contents)\n",
    "print(len(tokens), ' tokens available. Here are the 5 first in no particular order: ')\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IIPE.constants import ALL_STOP_WORDS\n",
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(frozenset, 398)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stop_words = text.ENGLISH_STOP_WORDS.union(ALL_STOP_WORDS)\n",
    "type(all_stop_words), len(all_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('the', 0.5043432782910858), ('of', 0.5043235898301934), ('and', 0.5043173740137139), ('to', 0.504246364895143), ('in', 0.5042323008293276), ('school', 0.504212296386216), ('pupils', 0.5041910954025344), ('is', 0.5041532723032424), ('learning', 0.5040995702859548), ('for', 0.5038913292821663)]\n",
      "Topic 1:\n",
      "[('the', 2.8700750994892403), ('of', 2.608140402596899), ('and', 2.4265474828374383), ('to', 1.7005286524812306), ('in', 1.65505920474929), ('school', 1.5144521845212247), ('pupils', 1.4617358444676518), ('is', 1.3782118639161736), ('learning', 1.2396058079979895), ('for', 0.997152044021224)]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer().fit(df_contents['text'])\n",
    "\n",
    "data_vectorized = vectorizer.transform(df_contents['text'])\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=2).fit(data_vectorized)\n",
    "\n",
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])\n",
    "        \n",
    "\n",
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('good', 0.5030952616665783), ('quality', 0.5030606191072694), ('leadership', 0.5029480532086316), ('development', 0.5029146845710577), ('skills', 0.5028311104615628), ('overall', 0.5028187117684683), ('principal', 0.5028096494995531), ('ensure', 0.5027500126708212), ('needs', 0.502745050318159), ('education', 0.5027438637019254)]\n",
      "Topic 1:\n",
      "[('good', 1.7637517043053446), ('quality', 1.5970291165339665), ('leadership', 1.2259758741460305), ('development', 1.0960112639191455), ('skills', 1.0449508574621453), ('principal', 1.0150251404910915), ('overall', 0.9982457526773381), ('needs', 0.9528415819557876), ('range', 0.9355884494672351), ('ensure', 0.929247922107451)]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=all_stop_words).fit(df_contents['text'])\n",
    "\n",
    "data_vectorized = vectorizer.transform(df_contents['text'])\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=2).fit(data_vectorized)\n",
    "\n",
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])\n",
    "        \n",
    "\n",
    "print_topics(lda_model, vectorizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3"
   },
   "source": [
    "## Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "sos": {
   "kernels": [
    [
     "Python 3",
     "python3",
     "python3",
     "",
     ""
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.21.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
